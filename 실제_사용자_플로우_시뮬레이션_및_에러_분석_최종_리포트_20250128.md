# 크루즈 가이드 실제 사용자 플로우 시뮬레이션 및 에러 분석 최종 리포트
**작성일**: 2025-01-28  
**분석 범위**: 모든 사용자 기능 + 100명 동시 사용 시나리오

---

## 📋 목차
1. [실제 사용자 플로우 단계별 시뮬레이션](#1-실제-사용자-플로우-단계별-시뮬레이션)
2. [단계별 발견된 에러 및 문제점](#2-단계별-발견된-에러-및-문제점)
3. [100명 동시 사용 시나리오 상세 분석](#3-100명-동시-사용-시나리오-상세-분석)
4. [코드 레벨 구체적 문제점](#4-코드-레벨-구체적-문제점)
5. [우선순위별 즉시 수정 사항](#5-우선순위별-즉시-수정-사항)

---

## 1. 실제 사용자 플로우 단계별 시뮬레이션

### 플로우 1: 신규 사용자 로그인 → 채팅 시작

#### 1.1 로그인 페이지 접속 (`/login`)
**코드 위치**: `app/login/page.tsx`

**시뮬레이션**:
1. 사용자가 로그인 페이지 접속
2. 이름, 전화번호, 비밀번호 입력
3. "로그인" 버튼 클릭
4. `/api/auth/login` 호출

**발견된 문제점**:
- ✅ 입력값 검증은 잘 되어 있음 (trim 처리)
- ⚠️ **에러 처리**: 네트워크 오류 시 `catch` 블록에서 처리하지만, 타임아웃 처리가 없음
- ⚠️ **중복 제출 방지**: 버튼 클릭 시 `disabled` 처리 없음 → 빠른 연타 시 중복 요청 가능

**100명 동시 로그인 시나리오**:
- Rate limiter가 IP 기반이라 동일 네트워크 사용자들이 모두 차단될 수 있음
- DB 연결 풀 부족 시 일부 사용자 로그인 실패

#### 1.2 로그인 API 처리 (`/api/auth/login`)
**코드 위치**: `app/api/auth/login/route.ts`

**시뮬레이션**:
1. Rate limit 체크
2. 사용자 조회 (Prisma)
3. 비밀번호 검증
4. 세션 생성
5. 응답 반환

**발견된 문제점**:
- 🔴 **Critical**: 세션 생성 시 race condition 가능성
  - 동일 사용자가 동시에 로그인하면 세션 충돌 가능
  - 트랜잭션 미사용
- 🔴 **Critical**: DB 연결 풀 설정 없음
  - `lib/prisma.ts`에 connection pool 설정 없음
  - 100명 동시 로그인 시 "Too many connections" 에러
- 🟠 **High**: Rate limiter가 메모리 기반
  - 서버 재시작 시 초기화
  - 여러 인스턴스 간 공유 불가

**100명 동시 로그인 시나리오**:
```
시나리오: 100명이 동시에 로그인 버튼 클릭
예상 에러:
1. Rate limiter가 IP 기반이라 동일 네트워크 사용자 차단
2. DB 연결 풀 부족 (기본 10개) → 90명 실패
3. 세션 생성 race condition → 일부 사용자 세션 무효화
```

#### 1.3 채팅 화면 로드 (`/chat`)
**코드 위치**: `app/chat/components/ChatInteractiveUI.tsx`

**시뮬레이션**:
1. 사용자 정보 로드 (`/api/user/profile`)
2. 활성 여행 조회 (`/api/trips/active`)
3. 접근 권한 확인 (`/api/user/access-check`)
4. 어필리에이트 몰 URL 확인 (`/api/user/affiliate-mall-url`)

**발견된 문제점**:
- 🟠 **High**: 4개의 API를 순차적으로 호출
  - 네트워크 지연 시 로딩 시간 증가
  - 하나라도 실패하면 전체 실패
- 🟡 **Medium**: 에러 발생 시 fallback 처리 부족
  - `catch` 블록에서 로깅만 하고 사용자에게 명확한 메시지 없음

**100명 동시 접속 시나리오**:
```
시나리오: 100명이 동시에 /chat 접속
예상 문제:
1. /api/user/profile 100개 동시 요청 → DB 부하
2. /api/trips/active 100개 동시 요청 → DB 부하
3. 응답 지연으로 인한 사용자 경험 저하
```

---

### 플로우 2: AI 채팅 기능 사용

#### 2.1 AI 채팅 메시지 전송
**코드 위치**: `app/api/chat/stream/route.ts`

**시뮬레이션**:
1. 사용자가 메시지 입력
2. `/api/chat/stream` 호출
3. RAG 검색 수행
4. 상품 정보 조회 (크루즈 관련 질문 시)
5. Gemini API 호출
6. 스트리밍 응답 반환

**발견된 문제점**:
- 🔴 **Critical**: RAG 검색과 상품 조회가 매 요청마다 수행
  - 캐싱 없음 → DB 부하 증가
  - 100명 동시 채팅 시 DB 쿼리 폭증
- 🔴 **Critical**: 버퍼 크기 제한 (1MB)
  - 긴 응답 시 데이터 손실 가능
  - 라인 499: `if (buffer.length > 1000000)`
- 🟠 **High**: Gemini API rate limit 처리 없음
  - 100명 동시 요청 시 API 제한 초과 가능
  - 재시도 로직 없음

**100명 동시 채팅 시나리오**:
```
시나리오: 100명이 동시에 AI 채팅 메시지 전송
예상 에러:
1. Gemini API rate limit 초과 (분당 요청 수 제한)
2. RAG 검색 100개 동시 실행 → DB 부하
3. 상품 정보 조회 100개 동시 실행 → DB 부하
4. 버퍼 오버플로우 (긴 응답 시)
5. 메모리 사용량 급증
```

---

### 플로우 3: 체크리스트 기능 사용

#### 3.1 체크리스트 조회
**코드 위치**: `app/api/checklist/route.ts` (GET)

**시뮬레이션**:
1. 사용자가 체크리스트 페이지 접속
2. `/api/checklist` 호출
3. DB에서 항목 조회
4. 응답 반환

**발견된 문제점**:
- 🟡 **Medium**: 트랜잭션 없음 (조회라서 문제 없음)
- 🟡 **Medium**: 캐싱 없음
  - 자주 조회되는 데이터인데 캐싱 없음

#### 3.2 체크리스트 항목 추가/수정/삭제
**코드 위치**: `app/api/checklist/route.ts` (POST, PATCH, DELETE)

**시뮬레이션**:
1. 사용자가 항목 추가/수정/삭제
2. API 호출
3. DB 업데이트

**발견된 문제점**:
- 🟠 **High**: 동시 업데이트 시 race condition 가능
  - 두 사용자가 동시에 같은 항목 수정 시 마지막 것만 저장 (Lost Update)
  - 트랜잭션 없음
- 🟡 **Medium**: 낙관적 잠금(Optimistic Locking) 없음

**100명 동시 체크리스트 사용 시나리오**:
```
시나리오: 100명이 동시에 체크리스트 항목 추가/수정
예상 문제:
1. 동시 업데이트로 인한 데이터 손실
2. DB 쓰기 부하
3. 응답 지연
```

---

### 플로우 4: 여행 가계부 기능 사용

#### 4.1 가계부 조회
**코드 위치**: `app/api/expenses/route.ts` (GET)

**시뮬레이션**:
1. 사용자가 가계부 페이지 접속
2. `/api/expenses` 호출
3. DB에서 지출 내역 조회
4. 응답 반환

**발견된 문제점**:
- 🟡 **Medium**: 캐싱 없음
- 🟡 **Medium**: 페이지네이션 없음
  - 지출 내역이 많으면 모든 데이터를 한 번에 로드

#### 4.2 가계부 지출 추가/수정
**코드 위치**: `app/api/expenses/route.ts` (POST, PUT)

**시뮬레이션**:
1. 사용자가 지출 추가/수정
2. API 호출
3. DB 저장/업데이트

**발견된 문제점**:
- 🟠 **High**: 트랜잭션 없음
  - 여러 필드 업데이트 시 부분 실패 가능
- 🟠 **High**: 동시 업데이트 시 race condition
  - 두 사용자가 동시에 같은 지출 수정 시 마지막 것만 저장

**100명 동시 가계부 사용 시나리오**:
```
시나리오: 100명이 동시에 지출 추가/수정
예상 문제:
1. 동시 업데이트로 인한 데이터 손실
2. DB 쓰기 부하
3. 트랜잭션 없어서 부분 실패 가능
```

---

### 플로우 5: 여권 업로드 기능

#### 5.1 여권 파일 업로드
**코드 위치**: `app/api/passport/[token]/upload/route.ts`

**시뮬레이션**:
1. 사용자가 여권 사진 업로드
2. 파일 크기 검증 (10MB 제한)
3. Google Drive에 업로드
4. DB에 메타데이터 저장

**발견된 문제점**:
- 🔴 **Critical**: 파일을 메모리에 전체 로드
  - 라인 75-76: `await file.arrayBuffer()` → 전체 파일을 메모리에 로드
  - 100명이 동시에 10MB 파일 업로드 시 1GB 메모리 사용
- 🔴 **Critical**: Google Drive API rate limit 처리 없음
  - 100명 동시 업로드 시 API 제한 초과
- 🟠 **High**: 업로드 큐 시스템 없음
  - 동시 업로드 제한 없음

**100명 동시 여권 업로드 시나리오**:
```
시나리오: 100명이 동시에 10MB 여권 사진 업로드
예상 에러:
1. 메모리 부족 (1GB 사용)
2. Google Drive API rate limit 초과
3. 서버 크래시 가능성
4. 업로드 실패 시 재시도 로직 없음
```

---

### 플로우 6: 통번역기 기능

#### 6.1 번역 요청
**코드 위치**: `app/api/chat/route.ts` (translate 모드)

**시뮬레이션**:
1. 사용자가 번역 요청
2. Gemini API 호출
3. 번역 결과 반환

**발견된 문제점**:
- 🟠 **High**: Gemini API rate limit 처리 없음
  - 100명 동시 번역 요청 시 API 제한 초과
- 🟡 **Medium**: 재시도 로직 있음 (최대 2회)
  - 하지만 rate limit 초과 시 재시도해도 실패

**100명 동시 번역 시나리오**:
```
시나리오: 100명이 동시에 번역 요청
예상 에러:
1. Gemini API rate limit 초과
2. 일부 사용자 번역 실패
3. 재시도해도 실패 (rate limit 때문)
```

---

## 2. 단계별 발견된 에러 및 문제점

### 🔴 Critical (즉시 수정 필요)

#### 2.1 데이터베이스 Connection Pool 미설정
**파일**: `lib/prisma.ts`
**현재 코드**:
```typescript
const prisma =
  globalThis.__prisma ??
  new PrismaClient({
    log: ['error', 'warn'],
  });
```

**문제점**:
- Connection pool 설정 없음
- 기본값으로 최대 10개 연결만 사용
- 100명 동시 사용 시 90명 실패

**해결 방안**:
```typescript
// DATABASE_URL에 추가 필요:
// ?connection_limit=50&pool_timeout=20&connect_timeout=10
```

#### 2.2 Rate Limiter가 메모리 기반
**파일**: `lib/rate-limiter.ts`
**문제점**:
- 메모리 기반 Map 사용
- 서버 재시작 시 초기화
- 여러 인스턴스 간 공유 불가

**해결 방안**:
- Redis 기반 rate limiter로 전환
- 또는 Vercel Edge Config 활용

#### 2.3 세션 생성 Race Condition
**파일**: `app/api/auth/login/route.ts`
**문제점**:
- 동시 로그인 시 세션 충돌 가능
- 트랜잭션 미사용

**해결 방안**:
- 세션 생성에 트랜잭션 적용
- 또는 분산 락 사용

#### 2.4 파일 업로드 메모리 문제
**파일**: `app/api/passport/[token]/upload/route.ts`
**문제점**:
- 전체 파일을 메모리에 로드
- 100명 동시 업로드 시 1GB 메모리 사용

**해결 방안**:
- 스트리밍 업로드로 변경
- 또는 Vercel Blob Storage 직접 사용

#### 2.5 AI 채팅 버퍼 오버플로우
**파일**: `app/api/chat/stream/route.ts`
**문제점**:
- 버퍼 크기 1MB 제한
- 긴 응답 시 데이터 손실

**해결 방안**:
- 버퍼 크기 증가 또는 스트리밍 방식 개선

### 🟠 High (우선 수정 권장)

#### 2.6 동시 업데이트 Race Condition
**파일**: `app/api/checklist/route.ts`, `app/api/expenses/route.ts`
**문제점**:
- 동시 업데이트 시 마지막 것만 저장 (Lost Update)
- 트랜잭션 없음

**해결 방안**:
- 낙관적 잠금(Optimistic Locking) 적용
- 또는 트랜잭션 사용

#### 2.7 Gemini API Rate Limit 처리 없음
**파일**: `app/api/chat/stream/route.ts`, `app/api/chat/route.ts`
**문제점**:
- Rate limit 초과 시 재시도 로직 없음
- 100명 동시 요청 시 대량 실패

**해결 방안**:
- 요청 큐 시스템 도입
- Rate limit 체크 및 재시도 로직

#### 2.8 캐싱 부재
**파일**: 여러 API 라우트
**문제점**:
- 자주 조회되는 데이터 캐싱 없음
- DB 부하 증가

**해결 방안**:
- Redis 캐싱 도입
- 또는 Next.js 캐싱 활용

### 🟡 Medium (점진적 개선)

#### 2.9 에러 핸들링 일관성 부족
**문제점**:
- 일부 API는 상세한 에러 처리, 일부는 간단한 처리
- 에러 메시지 형식 불일치

**해결 방안**:
- 통일된 에러 핸들링 미들웨어 도입

#### 2.10 페이지네이션 부재
**파일**: `app/api/expenses/route.ts`
**문제점**:
- 지출 내역이 많으면 모든 데이터를 한 번에 로드

**해결 방안**:
- 페이지네이션 추가

---

## 3. 100명 동시 사용 시나리오 상세 분석

### 시나리오 1: 100명 동시 로그인

**예상 문제**:
1. **DB 연결 풀 부족**
   - 현재 최대 10개 연결
   - 100명 중 90명 실패
   - 에러: "Too many connections"

2. **Rate Limiter 문제**
   - IP 기반 rate limiting
   - 동일 네트워크 사용자들 모두 차단
   - 에러: "Rate limit exceeded"

3. **세션 생성 Race Condition**
   - 동일 사용자 동시 로그인 시 세션 충돌
   - 일부 사용자 세션 무효화

**해결 방안**:
1. DB connection pool 확대 (최소 50개)
2. Rate limiter를 사용자 ID 기반으로 변경
3. 세션 생성에 트랜잭션 적용

---

### 시나리오 2: 100명 동시 AI 채팅

**예상 문제**:
1. **Gemini API Rate Limit**
   - 분당 요청 수 제한 초과
   - 일부 사용자 채팅 실패
   - 에러: "API rate limit exceeded"

2. **DB 부하**
   - RAG 검색 100개 동시 실행
   - 상품 정보 조회 100개 동시 실행
   - DB 쿼리 폭증

3. **메모리 사용량 급증**
   - 스트리밍 버퍼 100개
   - 메모리 부족 가능

**해결 방안**:
1. Gemini API 요청 큐 시스템
2. RAG 검색 결과 캐싱
3. 상품 정보 캐싱
4. 버퍼 크기 최적화

---

### 시나리오 3: 100명 동시 파일 업로드

**예상 문제**:
1. **메모리 부족**
   - 10MB × 100 = 1GB 메모리 사용
   - 서버 메모리 부족
   - 에러: "Out of memory"

2. **Google Drive API Rate Limit**
   - 100개 동시 업로드 시 API 제한 초과
   - 업로드 실패

3. **업로드 큐 없음**
   - 동시 업로드 제한 없음
   - 모든 요청이 동시에 처리 시도

**해결 방안**:
1. 업로드 큐 시스템 (최대 10개 동시 처리)
2. 파일 스트리밍 업로드
3. Google Drive API 재시도 로직

---

### 시나리오 4: 100명 동시 데이터 업데이트

**예상 문제**:
1. **Lost Update 문제**
   - 동시 업데이트 시 마지막 것만 저장
   - 데이터 손실

2. **DB 쓰기 부하**
   - 100개 동시 쓰기 요청
   - DB 성능 저하

3. **트랜잭션 없음**
   - 부분 실패 시 데이터 불일치

**해결 방안**:
1. 낙관적 잠금(Optimistic Locking) 적용
2. 트랜잭션 사용
3. 쓰기 요청 큐 시스템

---

## 4. 코드 레벨 구체적 문제점

### 4.1 Prisma Connection Pool 설정

**현재 코드** (`lib/prisma.ts`):
```typescript
const prisma =
  globalThis.__prisma ??
  new PrismaClient({
    log: ['error', 'warn'],
  });
```

**문제점**:
- Connection pool 설정 없음
- 기본값으로 최대 10개 연결

**수정 방안**:
```typescript
// DATABASE_URL에 추가:
// postgresql://...?connection_limit=50&pool_timeout=20&connect_timeout=10
```

### 4.2 Rate Limiter 메모리 기반

**현재 코드** (`lib/rate-limiter.ts`):
```typescript
class RateLimiter {
  private store: Map<string, RateLimitEntry> = new Map();
  // ...
}
```

**문제점**:
- 메모리 기반
- 서버 재시작 시 초기화
- 여러 인스턴스 간 공유 불가

**수정 방안**:
- Redis 기반으로 전환
- 또는 Vercel Edge Config 활용

### 4.3 파일 업로드 메모리 로드

**현재 코드** (`app/api/passport/[token]/upload/route.ts`):
```typescript
const arrayBuffer = await file.arrayBuffer();
const buffer = Buffer.from(arrayBuffer);
```

**문제점**:
- 전체 파일을 메모리에 로드
- 100명 동시 업로드 시 1GB 메모리 사용

**수정 방안**:
- 스트리밍 업로드로 변경
- 또는 Vercel Blob Storage 직접 사용

### 4.4 AI 채팅 버퍼 제한

**현재 코드** (`app/api/chat/stream/route.ts`):
```typescript
if (buffer.length > 1000000) { // 1MB 제한
  logger.warn('[Stream API] Buffer too large, truncating');
  buffer = buffer.substring(buffer.length - 500000);
}
```

**문제점**:
- 버퍼 크기 1MB 제한
- 긴 응답 시 데이터 손실

**수정 방안**:
- 버퍼 크기 증가 또는 스트리밍 방식 개선

### 4.5 동시 업데이트 Race Condition

**현재 코드** (`app/api/checklist/route.ts`):
```typescript
const updated = await prisma.checklistItem.update({
  where: { id: numericId },
  data: updateData,
});
```

**문제점**:
- 트랜잭션 없음
- 동시 업데이트 시 마지막 것만 저장

**수정 방안**:
- 낙관적 잠금(Optimistic Locking) 적용
- 또는 트랜잭션 사용

---

## 5. 우선순위별 즉시 수정 사항

### 🔴 Priority 1: 즉시 수정 (운영 안정성)

1. **DB Connection Pool 설정**
   - `DATABASE_URL`에 `?connection_limit=50&pool_timeout=20` 추가
   - 우선순위: 최우선

2. **Rate Limiter 개선**
   - Redis 기반으로 전환 (또는 Vercel Edge Config)
   - 사용자 ID 기반 rate limiting 추가
   - 우선순위: 최우선

3. **세션 생성 트랜잭션 적용**
   - `app/api/auth/login/route.ts` 수정
   - 우선순위: 최우선

4. **파일 업로드 메모리 최적화**
   - 스트리밍 업로드로 변경
   - 우선순위: 높음

5. **AI 채팅 버퍼 크기 증가**
   - 버퍼 크기 1MB → 5MB로 증가
   - 우선순위: 높음

### 🟠 Priority 2: 1주일 내 수정 (성능 개선)

6. **Gemini API 요청 큐 시스템**
   - 요청 큐 도입
   - Rate limit 체크 및 재시도 로직

7. **캐싱 도입**
   - Redis 캐싱
   - RAG 검색 결과 캐싱
   - 상품 정보 캐싱

8. **동시 업데이트 Race Condition 해결**
   - 낙관적 잠금(Optimistic Locking) 적용
   - 트랜잭션 사용

### 🟡 Priority 3: 점진적 개선 (장기 안정성)

9. **에러 핸들링 통일**
   - 공통 에러 핸들러 미들웨어 생성

10. **페이지네이션 추가**
    - 지출 내역 페이지네이션

11. **모니터링 강화**
    - 에러 추적 시스템 (Sentry)
    - 성능 모니터링

---

## 6. 체크리스트

### 즉시 확인 필요 사항
- [ ] `DATABASE_URL`에 connection pool 파라미터 확인
- [ ] Rate limiter가 프로덕션에서 제대로 작동하는지 확인
- [ ] 세션 쿠키 보안 설정 확인
- [ ] 파일 업로드 메모리 사용량 확인

### 성능 테스트 필요 사항
- [ ] 100명 동시 로그인 테스트
- [ ] 100명 동시 AI 채팅 테스트
- [ ] 100명 동시 파일 업로드 테스트
- [ ] DB 연결 풀 부족 시나리오 테스트
- [ ] Gemini API rate limit 테스트

### 모니터링 설정 필요 사항
- [ ] 에러 추적 시스템 연동
- [ ] 성능 메트릭 수집
- [ ] 알림 설정 (에러 발생 시)

---

## 7. 결론

현재 시스템은 기본적인 기능은 잘 구현되어 있으나, **100명 동시 사용 시나리오**에서는 다음과 같은 Critical 문제가 발생할 수 있습니다:

1. **DB 연결 풀 부족** - 가장 우선적으로 해결 필요
2. **Rate limiter 한계** - Redis 기반으로 전환 권장
3. **메모리 관리** - 파일 업로드 및 스트리밍 최적화 필요
4. **동시성 문제** - Race condition 해결 필요
5. **API Rate Limit** - 요청 큐 시스템 필요

**권장 사항**:
- Priority 1 항목부터 즉시 수정
- 각 단계마다 부하 테스트 수행
- 모니터링 시스템 구축 후 점진적 개선

---

**리포트 작성자**: AI Assistant  
**검토 필요**: 개발팀 리뷰 및 우선순위 조정


